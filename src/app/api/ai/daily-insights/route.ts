import { GoogleGenerativeAI } from '@google/generative-ai';
import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@supabase/supabase-js';

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!;
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY!;

// Simple in-memory cache
interface CacheEntry {
    insight: string;
    stats: any;
    generatedAt: string;
    date: string;
    locale: string;
}

let insightsCache: CacheEntry | null = null;
const CACHE_DURATION = 15 * 60 * 1000; // 15 minutes

export async function GET(request: NextRequest) {
    try {
        // Check if Gemini API key is available
        if (!process.env.GEMINI_API_KEY) {
            return NextResponse.json(
                { success: false, error: 'Gemini API Key is not configured' },
                { status: 500 }
            );
        }

        // Get date and locale from query params
        const { searchParams } = new URL(request.url);
        const dateParam = searchParams.get('date');
        const locale = searchParams.get('locale') || 'th';

        // Calculate Thailand time
        const now = new Date();
        const thailandOffset = 7 * 60;
        const localOffset = now.getTimezoneOffset();
        const thailandTime = new Date(now.getTime() + (thailandOffset + localOffset) * 60000);

        const today = dateParam || thailandTime.toISOString().split('T')[0];
        const yesterday = new Date(thailandTime.getTime() - 24 * 60 * 60 * 1000).toISOString().split('T')[0];

        // Check cache
        if (
            insightsCache &&
            insightsCache.date === today &&
            insightsCache.locale === locale &&
            (Date.now() - new Date(insightsCache.generatedAt).getTime() < CACHE_DURATION)
        ) {
            return NextResponse.json({
                success: true,
                data: {
                    insight: insightsCache.insight,
                    stats: insightsCache.stats,
                    generatedAt: insightsCache.generatedAt,
                }
            });
        }

        // Initialize Supabase
        const supabase = createClient(supabaseUrl, supabaseServiceKey);

        // Fetch today's reservations
        const { data: todayReservations, error: todayError } = await supabase
            .from('reservations')
            .select('*')
            .eq('reservation_date', today);

        if (todayError) throw todayError;

        // Fetch yesterday's reservations for comparison
        const { data: yesterdayReservations, error: yesterdayError } = await supabase
            .from('reservations')
            .select('*')
            .eq('reservation_date', yesterday);

        if (yesterdayError) throw yesterdayError;

        // Calculate statistics
        const stats = {
            today: {
                total: todayReservations?.length || 0,
                confirmed: todayReservations?.filter(r => r.status === 'confirmed').length || 0,
                pending: todayReservations?.filter(r => r.status === 'pending').length || 0,
                cancelled: todayReservations?.filter(r => r.status === 'cancelled').length || 0,
                totalGuests: todayReservations?.reduce((sum, r) => sum + (r.party_size || 0), 0) || 0,
            },
            yesterday: {
                total: yesterdayReservations?.length || 0,
                confirmed: yesterdayReservations?.filter(r => r.status === 'confirmed').length || 0,
                totalGuests: yesterdayReservations?.reduce((sum, r) => sum + (r.party_size || 0), 0) || 0,
            },
        };

        // Calculate peak hours
        const hourCounts: Record<number, number> = {};
        todayReservations?.forEach(r => {
            if (r.reservation_time) {
                const hour = parseInt(r.reservation_time.split(':')[0]);
                hourCounts[hour] = (hourCounts[hour] || 0) + 1;
            }
        });
        const peakHour = Object.entries(hourCounts).sort((a, b) => b[1] - a[1])[0];

        // Generate AI insight using Gemini
        const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

        // Models to try in order
        const modelsToTry = [
            'gemini-1.5-flash',
            'gemini-1.5-pro',
            'gemini-pro'
        ];

        let prompt;

        if (locale === 'en') {
            prompt = `
You are an AI assistant for a restaurant reservation system. Please create a short summary (2-3 sentences) in English based on the statistics below.

ðŸ“Š Today's Stats (${today}):
- Total bookings: ${stats.today.total}
- Confirmed: ${stats.today.confirmed}
- Pending: ${stats.today.pending}
- Cancelled: ${stats.today.cancelled}
- Expected guests: ${stats.today.totalGuests}
- Peak hour: ${peakHour ? `${peakHour[0]}:00 (${peakHour[1]} bookings)` : 'No data'}

ðŸ“ˆ Comparison with Yesterday (${yesterday}):
- Total bookings yesterday: ${stats.yesterday.total}
- Total guests yesterday: ${stats.yesterday.totalGuests}

Please provide a friendly, interesting short summary with appropriate emojis. Do not use markdown or bullet points.
`;
        } else {
            prompt = `
à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢ AI à¸ªà¸³à¸«à¸£à¸±à¸šà¸£à¸°à¸šà¸šà¸ˆà¸­à¸‡à¹‚à¸•à¹Šà¸°à¸£à¹‰à¸²à¸™à¸­à¸²à¸«à¸²à¸£ à¹‚à¸›à¸£à¸”à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸ªà¸£à¸¸à¸›à¸ªà¸±à¹‰à¸™à¹† (2-3 à¸›à¸£à¸°à¹‚à¸¢à¸„) à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢ à¸ˆà¸²à¸à¸ªà¸–à¸´à¸•à¸´à¸”à¹‰à¸²à¸™à¸¥à¹ˆà¸²à¸‡à¸™à¸µà¹‰

ðŸ“Š à¸ªà¸–à¸´à¸•à¸´à¸§à¸±à¸™à¸™à¸µà¹‰ (${today}):
- à¸à¸²à¸£à¸ˆà¸­à¸‡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”: ${stats.today.total} à¸£à¸²à¸¢à¸à¸²à¸£
- à¸¢à¸·à¸™à¸¢à¸±à¸™à¹à¸¥à¹‰à¸§: ${stats.today.confirmed} à¸£à¸²à¸¢à¸à¸²à¸£
- à¸£à¸­à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£: ${stats.today.pending} à¸£à¸²à¸¢à¸à¸²à¸£
- à¸¢à¸à¹€à¸¥à¸´à¸: ${stats.today.cancelled} à¸£à¸²à¸¢à¸à¸²à¸£
- à¸¥à¸¹à¸à¸„à¹‰à¸²à¸—à¸µà¹ˆà¸„à¸²à¸”à¸§à¹ˆà¸²à¸ˆà¸°à¸¡à¸²: ${stats.today.totalGuests} à¸„à¸™
- à¸Šà¹ˆà¸§à¸‡à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸¡à¸µà¸à¸²à¸£à¸ˆà¸­à¸‡à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”: ${peakHour ? `${peakHour[0]}:00 à¸™. (${peakHour[1]} à¸£à¸²à¸¢à¸à¸²à¸£)` : 'à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥'}

ðŸ“ˆ à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸šà¹€à¸¡à¸·à¹ˆà¸­à¸§à¸²à¸™ (${yesterday}):
- à¸à¸²à¸£à¸ˆà¸­à¸‡à¹€à¸¡à¸·à¹ˆà¸­à¸§à¸²à¸™: ${stats.yesterday.total} à¸£à¸²à¸¢à¸à¸²à¸£
- à¸¥à¸¹à¸à¸„à¹‰à¸²à¹€à¸¡à¸·à¹ˆà¸­à¸§à¸²à¸™: ${stats.yesterday.totalGuests} à¸„à¸™

à¸à¸£à¸¸à¸“à¸²à¸•à¸­à¸šà¹€à¸›à¹‡à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸ªà¸£à¸¸à¸›à¸ªà¸±à¹‰à¸™à¹† à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™à¸¡à¸´à¸•à¸£à¹à¸¥à¸°à¸™à¹ˆà¸²à¸ªà¸™à¹ƒà¸ˆ à¸žà¸£à¹‰à¸­à¸¡ emoji à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡ à¸«à¹‰à¸²à¸¡à¹ƒà¸Šà¹‰ markdown à¸«à¸£à¸·à¸­ bullet points
`;
        }

        try {
            // Helper for delay
            const delay = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

            // Recursive function to try models with retry logic
            const generateWithFallback = async (modelIndex = 0, retryCount = 0): Promise<string> => {
                const modelName = modelsToTry[modelIndex];

                // If we ran out of models, throw error to trigger fallback
                if (!modelName) {
                    throw new Error('All AI models failed');
                }

                try {
                    console.log(`Attempting to generate with model: ${modelName} (Retry: ${retryCount})`);
                    const modelInstance = genAI.getGenerativeModel({ model: modelName });
                    const result = await modelInstance.generateContent(prompt);
                    return result.response.text().trim();
                } catch (error: any) {
                    const isRateLimit = error.message?.includes('429') || error.status === 429;
                    const isQuotaExceeded = error.message?.includes('quota') || error.message?.includes('limit');

                    // If Rate Limit/Quota issue
                    if (isRateLimit || isQuotaExceeded) {
                        console.warn(`Model ${modelName} hit rate limit/quota.`);

                        // If we can still retry this model (up to 1 time for transient errors), do it
                        // But mostly for rate limits we want to switch models fast if it persists
                        if (retryCount < 1) {
                            await delay(1000); // Wait 1s
                            return generateWithFallback(modelIndex, retryCount + 1);
                        }

                        // Move to next model
                        return generateWithFallback(modelIndex + 1, 0);
                    }

                    // For other errors, also try next model just in case
                    console.error(`Model ${modelName} error:`, error.message);
                    return generateWithFallback(modelIndex + 1, 0);
                }
            };

            const insight = await generateWithFallback();

            // Update cache
            insightsCache = {
                insight,
                stats,
                generatedAt: new Date().toISOString(),
                date: today,
                locale
            };

            return NextResponse.json({
                success: true,
                data: {
                    insight,
                    stats,
                    generatedAt: insightsCache.generatedAt,
                }
            });

        } catch (error: any) {
            // Handle Rate Limit gracefully by returning stats without AI text
            if (error.message?.includes('429') || error.status === 429) {
                console.warn('Gemini Rate Limit hit after retries. Returning fallback stats.');
                const fallbackInsight = locale === 'en'
                    ? "AI is currently experimenting high traffic. Here are your latest stats:"
                    : "à¸‚à¸“à¸°à¸™à¸µà¹‰à¸¡à¸µà¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ AI à¸ˆà¸³à¸™à¸§à¸™à¸¡à¸²à¸ à¹‚à¸›à¸£à¸”à¸”à¸¹à¸ªà¸–à¸´à¸•à¸´à¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¸‚à¸­à¸‡à¸„à¸¸à¸“à¹„à¸”à¹‰à¸—à¸µà¹ˆà¸™à¸µà¹ˆ:";

                return NextResponse.json({
                    success: true,
                    data: {
                        insight: fallbackInsight,
                        stats,
                        generatedAt: new Date().toISOString(),
                    }
                });
            }
            throw error; // Re-throw other errors to be caught by outer catch
        }

    } catch (error: any) {
        console.error('AI Insights error:', error);
        return NextResponse.json(
            { success: false, error: error.message || 'Failed to generate insights' },
            { status: 500 }
        );
    }
}
